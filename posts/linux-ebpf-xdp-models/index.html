<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>XDP 挂载模式剖析 | rand0m's blog</title><meta name=keywords content="Networking,Linux,Kernel,C,eBPF,XDP"><meta name=description content="XDP挂载模式对比
了解XDP的读者应该知道：XDP是基于eBPF的一个高性能网络路径技术，它的原理就是在数据包处理的早期阶段（在内核网络协议栈之前）挂载eBPF程序对数据包进行处理，从而实现高效的网络数据包处理。如果你写过XDP程序，那么一定知道挂载XDP的时候有多种模式可选，不同模式之间的效率不同。这篇文章我们就来深入剖析一下XDP的集中模式之间到底有哪些区别。
首先看看XDP挂载模式有哪几种？不同的挂载模式有和区别？
XDP挂载模式可以以三种方式挂在到网卡上：

  
      
          
          Generic
          Native
          Offloaded
      
  
  
      
          兼容性
          兼容所有网络设备
          需要网卡驱动显示支持XDP
          特定的可编程网卡
      
      
          执行阶段
          在网络核心代码中执行（此时已经分配了SKB）
          在网卡驱动中执行（还未分配SKB）
          网卡执行，CPU零开销
      
      
          性能
          较低
          高
          最高
      
  

XDP 挂载原理
XDP程序是挂载在网络数据包的处理路径上的，所以我们有必要先对网络数据包的处理路径有一个整体的掌握（这里插播一条小广告，我之前写过一篇分析数据包从网卡到内核协议栈的博客）。
数据包从网卡到内核网络协议栈的流程可以分为以下几个步骤：

数据包到达网卡 网卡硬件接收以太帧，做基本校验（如 CRC）。
DMA 写入内存 网卡通过 DMA 将数据包写入驱动预先分配好的接收缓冲区（Descriptor Ring）。
中断通知 CPU 网卡通过 IRQ 告诉 CPU：“我收到了新数据包”。
驱动中断处理函数（ISR） 驱动快速处理中断，通常只是调用 __napi_schedule()，把 NAPI poll 加入调度队列。
软中断调度 NAPI poll CPU 执行 do_softirq() → net_rx_action() → 调用 网卡的的 poll 函数。
poll 函数提取数据包并构造 skb 驱动在 poll 中读取 DMA ring 的描述符，把数据包封装进 sk_buff 结构，交给网络核心层。
网络核心层处理 网络核心层根据数据包格式选择对应的协议栈，然后交给协议栈处理。

XDP就是挂载在上面的某个阶段，从而实现高效网络数据包处理的。具体来说Native模式的XDP是在网卡的驱动程序中执行的（对应步骤6），而Generic模式的XDP是在网络核心层中执行的（对应步骤7）。这也说明了Native模式的性能比Generic模式高。"><meta name=author content="rand0m"><link rel=canonical href=https://rand0m42195.github.io/posts/linux-ebpf-xdp-models/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://rand0m42195.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rand0m42195.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rand0m42195.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://rand0m42195.github.io/apple-touch-icon.png><link rel=mask-icon href=https://rand0m42195.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://rand0m42195.github.io/posts/linux-ebpf-xdp-models/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://rand0m42195.github.io/posts/linux-ebpf-xdp-models/"><meta property="og:site_name" content="rand0m's blog"><meta property="og:title" content="XDP 挂载模式剖析"><meta property="og:description" content="XDP挂载模式对比 了解XDP的读者应该知道：XDP是基于eBPF的一个高性能网络路径技术，它的原理就是在数据包处理的早期阶段（在内核网络协议栈之前）挂载eBPF程序对数据包进行处理，从而实现高效的网络数据包处理。如果你写过XDP程序，那么一定知道挂载XDP的时候有多种模式可选，不同模式之间的效率不同。这篇文章我们就来深入剖析一下XDP的集中模式之间到底有哪些区别。
首先看看XDP挂载模式有哪几种？不同的挂载模式有和区别？
XDP挂载模式可以以三种方式挂在到网卡上：
Generic Native Offloaded 兼容性 兼容所有网络设备 需要网卡驱动显示支持XDP 特定的可编程网卡 执行阶段 在网络核心代码中执行（此时已经分配了SKB） 在网卡驱动中执行（还未分配SKB） 网卡执行，CPU零开销 性能 较低 高 最高 XDP 挂载原理 XDP程序是挂载在网络数据包的处理路径上的，所以我们有必要先对网络数据包的处理路径有一个整体的掌握（这里插播一条小广告，我之前写过一篇分析数据包从网卡到内核协议栈的博客）。
数据包从网卡到内核网络协议栈的流程可以分为以下几个步骤：
数据包到达网卡 网卡硬件接收以太帧，做基本校验（如 CRC）。 DMA 写入内存 网卡通过 DMA 将数据包写入驱动预先分配好的接收缓冲区（Descriptor Ring）。 中断通知 CPU 网卡通过 IRQ 告诉 CPU：“我收到了新数据包”。 驱动中断处理函数（ISR） 驱动快速处理中断，通常只是调用 __napi_schedule()，把 NAPI poll 加入调度队列。 软中断调度 NAPI poll CPU 执行 do_softirq() → net_rx_action() → 调用 网卡的的 poll 函数。 poll 函数提取数据包并构造 skb 驱动在 poll 中读取 DMA ring 的描述符，把数据包封装进 sk_buff 结构，交给网络核心层。 网络核心层处理 网络核心层根据数据包格式选择对应的协议栈，然后交给协议栈处理。 XDP就是挂载在上面的某个阶段，从而实现高效网络数据包处理的。具体来说Native模式的XDP是在网卡的驱动程序中执行的（对应步骤6），而Generic模式的XDP是在网络核心层中执行的（对应步骤7）。这也说明了Native模式的性能比Generic模式高。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-25T11:12:40+08:00"><meta property="article:modified_time" content="2025-09-25T11:12:40+08:00"><meta property="article:tag" content="Networking"><meta property="article:tag" content="Linux"><meta property="article:tag" content="Kernel"><meta property="article:tag" content="C"><meta property="article:tag" content="EBPF"><meta property="article:tag" content="XDP"><meta name=twitter:card content="summary"><meta name=twitter:title content="XDP 挂载模式剖析"><meta name=twitter:description content="XDP挂载模式对比
了解XDP的读者应该知道：XDP是基于eBPF的一个高性能网络路径技术，它的原理就是在数据包处理的早期阶段（在内核网络协议栈之前）挂载eBPF程序对数据包进行处理，从而实现高效的网络数据包处理。如果你写过XDP程序，那么一定知道挂载XDP的时候有多种模式可选，不同模式之间的效率不同。这篇文章我们就来深入剖析一下XDP的集中模式之间到底有哪些区别。
首先看看XDP挂载模式有哪几种？不同的挂载模式有和区别？
XDP挂载模式可以以三种方式挂在到网卡上：

  
      
          
          Generic
          Native
          Offloaded
      
  
  
      
          兼容性
          兼容所有网络设备
          需要网卡驱动显示支持XDP
          特定的可编程网卡
      
      
          执行阶段
          在网络核心代码中执行（此时已经分配了SKB）
          在网卡驱动中执行（还未分配SKB）
          网卡执行，CPU零开销
      
      
          性能
          较低
          高
          最高
      
  

XDP 挂载原理
XDP程序是挂载在网络数据包的处理路径上的，所以我们有必要先对网络数据包的处理路径有一个整体的掌握（这里插播一条小广告，我之前写过一篇分析数据包从网卡到内核协议栈的博客）。
数据包从网卡到内核网络协议栈的流程可以分为以下几个步骤：

数据包到达网卡 网卡硬件接收以太帧，做基本校验（如 CRC）。
DMA 写入内存 网卡通过 DMA 将数据包写入驱动预先分配好的接收缓冲区（Descriptor Ring）。
中断通知 CPU 网卡通过 IRQ 告诉 CPU：“我收到了新数据包”。
驱动中断处理函数（ISR） 驱动快速处理中断，通常只是调用 __napi_schedule()，把 NAPI poll 加入调度队列。
软中断调度 NAPI poll CPU 执行 do_softirq() → net_rx_action() → 调用 网卡的的 poll 函数。
poll 函数提取数据包并构造 skb 驱动在 poll 中读取 DMA ring 的描述符，把数据包封装进 sk_buff 结构，交给网络核心层。
网络核心层处理 网络核心层根据数据包格式选择对应的协议栈，然后交给协议栈处理。

XDP就是挂载在上面的某个阶段，从而实现高效网络数据包处理的。具体来说Native模式的XDP是在网卡的驱动程序中执行的（对应步骤6），而Generic模式的XDP是在网络核心层中执行的（对应步骤7）。这也说明了Native模式的性能比Generic模式高。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rand0m42195.github.io/posts/"},{"@type":"ListItem","position":2,"name":"XDP 挂载模式剖析","item":"https://rand0m42195.github.io/posts/linux-ebpf-xdp-models/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"XDP 挂载模式剖析","name":"XDP 挂载模式剖析","description":"XDP挂载模式对比 了解XDP的读者应该知道：XDP是基于eBPF的一个高性能网络路径技术，它的原理就是在数据包处理的早期阶段（在内核网络协议栈之前）挂载eBPF程序对数据包进行处理，从而实现高效的网络数据包处理。如果你写过XDP程序，那么一定知道挂载XDP的时候有多种模式可选，不同模式之间的效率不同。这篇文章我们就来深入剖析一下XDP的集中模式之间到底有哪些区别。\n首先看看XDP挂载模式有哪几种？不同的挂载模式有和区别？\nXDP挂载模式可以以三种方式挂在到网卡上：\nGeneric Native Offloaded 兼容性 兼容所有网络设备 需要网卡驱动显示支持XDP 特定的可编程网卡 执行阶段 在网络核心代码中执行（此时已经分配了SKB） 在网卡驱动中执行（还未分配SKB） 网卡执行，CPU零开销 性能 较低 高 最高 XDP 挂载原理 XDP程序是挂载在网络数据包的处理路径上的，所以我们有必要先对网络数据包的处理路径有一个整体的掌握（这里插播一条小广告，我之前写过一篇分析数据包从网卡到内核协议栈的博客）。\n数据包从网卡到内核网络协议栈的流程可以分为以下几个步骤：\n数据包到达网卡 网卡硬件接收以太帧，做基本校验（如 CRC）。 DMA 写入内存 网卡通过 DMA 将数据包写入驱动预先分配好的接收缓冲区（Descriptor Ring）。 中断通知 CPU 网卡通过 IRQ 告诉 CPU：“我收到了新数据包”。 驱动中断处理函数（ISR） 驱动快速处理中断，通常只是调用 __napi_schedule()，把 NAPI poll 加入调度队列。 软中断调度 NAPI poll CPU 执行 do_softirq() → net_rx_action() → 调用 网卡的的 poll 函数。 poll 函数提取数据包并构造 skb 驱动在 poll 中读取 DMA ring 的描述符，把数据包封装进 sk_buff 结构，交给网络核心层。 网络核心层处理 网络核心层根据数据包格式选择对应的协议栈，然后交给协议栈处理。 XDP就是挂载在上面的某个阶段，从而实现高效网络数据包处理的。具体来说Native模式的XDP是在网卡的驱动程序中执行的（对应步骤6），而Generic模式的XDP是在网络核心层中执行的（对应步骤7）。这也说明了Native模式的性能比Generic模式高。\n","keywords":["Networking","Linux","Kernel","C","eBPF","XDP"],"articleBody":"XDP挂载模式对比 了解XDP的读者应该知道：XDP是基于eBPF的一个高性能网络路径技术，它的原理就是在数据包处理的早期阶段（在内核网络协议栈之前）挂载eBPF程序对数据包进行处理，从而实现高效的网络数据包处理。如果你写过XDP程序，那么一定知道挂载XDP的时候有多种模式可选，不同模式之间的效率不同。这篇文章我们就来深入剖析一下XDP的集中模式之间到底有哪些区别。\n首先看看XDP挂载模式有哪几种？不同的挂载模式有和区别？\nXDP挂载模式可以以三种方式挂在到网卡上：\nGeneric Native Offloaded 兼容性 兼容所有网络设备 需要网卡驱动显示支持XDP 特定的可编程网卡 执行阶段 在网络核心代码中执行（此时已经分配了SKB） 在网卡驱动中执行（还未分配SKB） 网卡执行，CPU零开销 性能 较低 高 最高 XDP 挂载原理 XDP程序是挂载在网络数据包的处理路径上的，所以我们有必要先对网络数据包的处理路径有一个整体的掌握（这里插播一条小广告，我之前写过一篇分析数据包从网卡到内核协议栈的博客）。\n数据包从网卡到内核网络协议栈的流程可以分为以下几个步骤：\n数据包到达网卡 网卡硬件接收以太帧，做基本校验（如 CRC）。 DMA 写入内存 网卡通过 DMA 将数据包写入驱动预先分配好的接收缓冲区（Descriptor Ring）。 中断通知 CPU 网卡通过 IRQ 告诉 CPU：“我收到了新数据包”。 驱动中断处理函数（ISR） 驱动快速处理中断，通常只是调用 __napi_schedule()，把 NAPI poll 加入调度队列。 软中断调度 NAPI poll CPU 执行 do_softirq() → net_rx_action() → 调用 网卡的的 poll 函数。 poll 函数提取数据包并构造 skb 驱动在 poll 中读取 DMA ring 的描述符，把数据包封装进 sk_buff 结构，交给网络核心层。 网络核心层处理 网络核心层根据数据包格式选择对应的协议栈，然后交给协议栈处理。 XDP就是挂载在上面的某个阶段，从而实现高效网络数据包处理的。具体来说Native模式的XDP是在网卡的驱动程序中执行的（对应步骤6），而Generic模式的XDP是在网络核心层中执行的（对应步骤7）。这也说明了Native模式的性能比Generic模式高。\n下面我们就以Intel的igb网卡为例，结合Linux内核（v5.10.244）源码分析igb网卡的Native模式和Generic模式的区别。\nXDP Native Model 现代的Linux内核使用了NAPI技术，将网络数据包的处理分为了上半部和下半部。上半部只处理最紧急的事情，而具体的处理则交给下半部处理。为了提高效率，NAPI采用poll（轮询）的方式处理数据包，而每个网卡都要注册自己的poll函数，igb网卡的poll函数就是igb_poll()，在igb_poll()会调用igb_clean_rx_irq()处理网卡收到的数据包。\n/** * igb_poll - NAPI Rx polling callback * @napi: napi polling structure * @budget: count of how many packets we should handle **/ static int igb_poll(struct napi_struct *napi, int budget) { struct igb_q_vector *q_vector = container_of(napi, struct igb_q_vector, napi); // ...... if (q_vector-\u003erx.ring) { // 处理接收到的网络数据包 int cleaned = igb_clean_rx_irq(q_vector, budget);\t} // ...... return work_done; } 追踪到igb_clean_rx_irq()中就可以看到igb_run_xdp()，即调用Native模式的XDP程序，而且调用igb_run_xdp()的时候skb还没有分配，如果XDP程序的执行结果是XDP_DROP，则会直接丢弃数据包，省去了分配skb的消耗。但如果执行结果是XDP_PASS，就会继续执行后续的处理动作，最终igb的驱动会调napi_gro_receive()处理skb。\nstatic int igb_clean_rx_irq(struct igb_q_vector *q_vector, const int budget) { struct igb_adapter *adapter = q_vector-\u003eadapter; struct igb_ring *rx_ring = q_vector-\u003erx.ring; struct sk_buff *skb = rx_ring-\u003eskb; unsigned int total_bytes = 0, total_packets = 0; u16 cleaned_count = igb_desc_unused(rx_ring); unsigned int xdp_xmit = 0; struct xdp_buff xdp; int rx_buf_pgcnt; xdp.rxq = \u0026rx_ring-\u003exdp_rxq; while (likely(total_packets \u003c budget)) { union e1000_adv_rx_desc *rx_desc; struct igb_rx_buffer *rx_buffer; unsigned int size; // ...... rx_buffer = igb_get_rx_buffer(rx_ring, size, \u0026rx_buf_pgcnt); /* retrieve a buffer from the ring */ if (!skb) {\t// 没有分配skb，将xdp结构体的成员赋值，为调用XDP做准备 xdp.data = page_address(rx_buffer-\u003epage) + rx_buffer-\u003epage_offset; xdp.data_meta = xdp.data; xdp.data_hard_start = xdp.data - igb_rx_offset(rx_ring); xdp.data_end = xdp.data + size; // !!! 这里执行了XDP程序 skb = igb_run_xdp(adapter, rx_ring, \u0026xdp); } // skb交给napi_gro_receive处理, Generic XDP就是在这里被执行的 napi_gro_receive(\u0026q_vector-\u003enapi, skb); /* reset skb pointer */ skb = NULL; } } igb_run_xdp()的逻辑比较简单，就是判断是否挂载了XDP程序，如果挂载了，就执行挂载的XDP程序，然后对返回的动作处理。\nstatic struct sk_buff *igb_run_xdp(struct igb_adapter *adapter, struct igb_ring *rx_ring, struct xdp_buff *xdp) { int err, result = IGB_XDP_PASS; struct bpf_prog *xdp_prog; u32 act; rcu_read_lock(); xdp_prog = READ_ONCE(rx_ring-\u003exdp_prog); if (!xdp_prog)\t// 如果没有挂载XDP，直接返回 goto xdp_out; prefetchw(xdp-\u003edata_hard_start); /* xdp_frame write */ // 执行XDP程序，根据执行结果设置返回值 act = bpf_prog_run_xdp(xdp_prog, xdp); switch (act) { case XDP_PASS: break; case XDP_TX: result = igb_xdp_xmit_back(adapter, xdp); if (result == IGB_XDP_CONSUMED) goto out_failure; break; case XDP_REDIRECT: err = xdp_do_redirect(adapter-\u003enetdev, xdp, xdp_prog); if (err) goto out_failure; result = IGB_XDP_REDIR; break; default: bpf_warn_invalid_xdp_action(act); fallthrough; case XDP_ABORTED: out_failure: trace_xdp_exception(rx_ring-\u003enetdev, xdp_prog, act); fallthrough; case XDP_DROP: result = IGB_XDP_CONSUMED; break; } xdp_out: rcu_read_unlock(); return ERR_PTR(-result); } 通过分析源码，我们知道了Native模式高效的原因就是它的在数据包处理的早期阶段执行，这个时候还没有为数据包分配skb。\nXDP Generic Model napi_gro_receive() 会调用napi_skb_finish()处理skb。\n上面在分析igb的poll函数时，我们看到了igb_poll()会调用igb_clean_rx_irq()处理数据包，igb_rx_irq()最终会将skb交给napi_gro_receive()，下面是napi_gro_receive()的实现，它会调用其他函数，最终会调用到do_xdp_generic()函数执行以Generic模式挂载的XDP程序。\ngro_result_t napi_gro_receive(struct napi_struct *napi, struct sk_buff *skb) { gro_result_t ret; skb_mark_napi_id(skb, napi); trace_napi_gro_receive_entry(skb); skb_gro_reset_offset(skb, 0); // 处理skb ret = napi_skb_finish(napi, skb, dev_gro_receive(napi, skb)); trace_napi_gro_receive_exit(ret); return ret; } EXPORT_SYMBOL(napi_gro_receive); 从napi_gro_receive()到do_xdp_generic()的调用链非常长，所以下面就以一个图片来展示这个调用链。\n通过上面的调用链可以看到do_xdp_generic()是被__netif_receive_skb_core()调用的。__netif_receive_skb_core()干了很多事情，包括：\n执行Generic XDP程序； 执行tcpdump抓包指令； 执行挂载在tc ingress上的程序； 执行挂载在netfilter ingress上的程序； 分发给对应的网络协议栈； 从这个函数可以清晰的看到XDP、tcpdump、tc ingress、netfilter和网络协议栈的顺序关系。\nstatic int __netif_receive_skb_core(struct sk_buff **pskb, bool pfmemalloc, struct packet_type **ppt_prev) { if (static_branch_unlikely(\u0026generic_xdp_needed_key)) { // Generic model XDP program执行点!!! ret2 = do_xdp_generic(rcu_dereference(skb-\u003edev-\u003exdp_prog), skb); if (ret2 != XDP_PASS) { ret = NET_RX_DROP; goto out; } } // tcpdump抓包的地方 list_for_each_entry_rcu(ptype, \u0026ptype_all, list) { if (pt_prev) ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = ptype; } list_for_each_entry_rcu(ptype, \u0026skb-\u003edev-\u003eptype_all, list) { if (pt_prev) ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = ptype; } #ifdef CONFIG_NET_INGRESS if (static_branch_unlikely(\u0026ingress_needed_key)) { bool another = false; // tc ingress执行点 skb = sch_handle_ingress(skb, \u0026pt_prev, \u0026ret, orig_dev, \u0026another); if (another) goto another_round; if (!skb) goto out; // netfilter ingress执行点 if (nf_ingress(skb, \u0026pt_prev, \u0026ret, orig_dev) \u003c 0) goto out; } #endif // ...... type = skb-\u003eprotocol; /* deliver only exact match when indicated */ // IP数据包在此被分发到内核协议栈处理 if (likely(!deliver_exact)) { deliver_ptype_list_skb(skb, \u0026pt_prev, orig_dev, type, \u0026ptype_base[ntohs(type) \u0026 PTYPE_HASH_MASK]); } // ...... } 总结 这篇文章结合Linux源码分析了XDP的Native和Generic模式两种模式的区别：Native模式是在网卡的驱动中执行的，执行的时候还未分配skb，这也要求必须网卡驱动支持XDP才能以Native模式挂载。Generic模式是在网络核心层执行的，此时已经分配了skb，虽然性能不如Native模式，但是仍然在tcpdump和协议栈之前。\n参考 The eXpress Data Path: Fast Programmable Packet Processing in the Operating System Kernel Linux kernel v5.10.244 source ","wordCount":"566","inLanguage":"zh","datePublished":"2025-09-25T11:12:40+08:00","dateModified":"2025-09-25T11:12:40+08:00","author":{"@type":"Person","name":"rand0m"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rand0m42195.github.io/posts/linux-ebpf-xdp-models/"},"publisher":{"@type":"Organization","name":"rand0m's blog","logo":{"@type":"ImageObject","url":"https://rand0m42195.github.io/favicon.ico"}}}</script><link rel=icon href=/favicon.ico type=image/x-icon><link rel=icon href=/favicon-16x16.png type=image/png size=16x16><link rel=icon href=/favicon-32x32.png type=image/png size=32x32><link rel=icon href=/favicon-192x192.png type=image/png size=192x192><link rel=icon href=/favicon-512x512.png type=image/png size=512x512></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rand0m42195.github.io/ accesskey=h title="rand0m's blog (Alt + H)">rand0m's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rand0m42195.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://rand0m42195.github.io/about/ title=关于><span>关于</span></a></li><li><a href=https://github.com/rand0m42195 title=GitHub><span>GitHub</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://rand0m42195.github.io/>主页</a>&nbsp;»&nbsp;<a href=https://rand0m42195.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">XDP 挂载模式剖析</h1><div class=post-meta><span title='2025-09-25 11:12:40 +0800 +0800'>九月 25, 2025</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;rand0m</div></header><div class=post-content><h2 id=xdp挂载模式对比>XDP挂载模式对比<a hidden class=anchor aria-hidden=true href=#xdp挂载模式对比>#</a></h2><p>了解<code>XDP</code>的读者应该知道：<code>XDP</code>是基于<code>eBPF</code>的一个高性能网络路径技术，它的原理就是在数据包处理的早期阶段（在内核网络协议栈之前）挂载<code>eBPF</code>程序对数据包进行处理，从而实现高效的网络数据包处理。如果你写过<code>XDP</code>程序，那么一定知道挂载<code>XDP</code>的时候有多种模式可选，不同模式之间的效率不同。这篇文章我们就来深入剖析一下<code>XDP</code>的集中模式之间到底有哪些区别。</p><p>首先看看<code>XDP</code>挂载模式有哪几种？不同的挂载模式有和区别？</p><p><code>XDP</code>挂载模式可以以三种方式挂在到网卡上：</p><table><thead><tr><th></th><th>Generic</th><th>Native</th><th>Offloaded</th></tr></thead><tbody><tr><td><strong>兼容性</strong></td><td>兼容所有网络设备</td><td>需要网卡驱动显示支持XDP</td><td>特定的可编程网卡</td></tr><tr><td><strong>执行阶段</strong></td><td>在网络核心代码中执行（此时已经分配了SKB）</td><td>在网卡驱动中执行（还未分配SKB）</td><td>网卡执行，CPU零开销</td></tr><tr><td><strong>性能</strong></td><td>较低</td><td>高</td><td>最高</td></tr></tbody></table><h2 id=xdp-挂载原理>XDP 挂载原理<a hidden class=anchor aria-hidden=true href=#xdp-挂载原理>#</a></h2><p>XDP程序是挂载在网络数据包的处理路径上的，所以我们有必要先对网络数据包的处理路径有一个整体的掌握（这里插播一条小广告，我之前写过一篇分析<a href=https://rand0m42195.github.io/posts/linux-networking-receive/>数据包从网卡到内核协议栈</a>的博客）。</p><p>数据包从网卡到内核网络协议栈的流程可以分为以下几个步骤：</p><ol><li><strong>数据包到达网卡</strong> 网卡硬件接收以太帧，做基本校验（如 CRC）。</li><li><strong>DMA 写入内存</strong> 网卡通过 DMA 将数据包写入驱动预先分配好的接收缓冲区（Descriptor Ring）。</li><li><strong>中断通知 CPU</strong> 网卡通过 IRQ 告诉 CPU：“我收到了新数据包”。</li><li><strong>驱动中断处理函数（ISR）</strong> 驱动快速处理中断，通常只是调用 <code>__napi_schedule()</code>，把 NAPI poll 加入调度队列。</li><li><strong>软中断调度 NAPI poll</strong> CPU 执行 <code>do_softirq()</code> → <code>net_rx_action()</code> → 调用 网卡的的 poll 函数。</li><li><strong>poll 函数提取数据包并构造 skb</strong> 驱动在 poll 中读取 DMA ring 的描述符，把数据包封装进 <code>sk_buff</code> 结构，交给网络核心层。</li><li><strong>网络核心层处理</strong> 网络核心层根据数据包格式选择对应的协议栈，然后交给协议栈处理。</li></ol><p>XDP就是挂载在上面的某个阶段，从而实现高效网络数据包处理的。具体来说<em>Native</em>模式的<code>XDP</code>是在网卡的驱动程序中执行的（对应步骤6），而Generic模式的XDP是在网络核心层中执行的（对应步骤7）。这也说明了<em>Native</em>模式的性能比<em>Generic</em>模式高。</p><p>下面我们就以Intel的<strong>igb</strong>网卡为例，结合Linux内核（v5.10.244）源码分析igb网卡的<em>Native</em>模式和<em>Generic</em>模式的区别。</p><h3 id=xdp-native-model>XDP Native Model<a hidden class=anchor aria-hidden=true href=#xdp-native-model>#</a></h3><p>现代的Linux内核使用了NAPI技术，将网络数据包的处理分为了上半部和下半部。上半部只处理最紧急的事情，而具体的处理则交给下半部处理。为了提高效率，NAPI采用poll（轮询）的方式处理数据包，而每个网卡都要注册自己的poll函数，igb网卡的poll函数就是<a href=https://elixir.bootlin.com/linux/v5.10.244/source/drivers/net/ethernet/intel/igb/igb_main.c#L8034><code>igb_poll()</code></a>，在<code>igb_poll()</code>会调用<code>igb_clean_rx_irq()</code>处理网卡收到的数据包。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=cm>/**
</span></span></span><span class=line><span class=cl><span class=cm> *  igb_poll - NAPI Rx polling callback
</span></span></span><span class=line><span class=cl><span class=cm> *  @napi: napi polling structure
</span></span></span><span class=line><span class=cl><span class=cm> *  @budget: count of how many packets we should handle
</span></span></span><span class=line><span class=cl><span class=cm> **/</span>
</span></span><span class=line><span class=cl><span class=k>static</span> <span class=kt>int</span> <span class=nf>igb_poll</span><span class=p>(</span><span class=k>struct</span> <span class=n>napi_struct</span> <span class=o>*</span><span class=n>napi</span><span class=p>,</span> <span class=kt>int</span> <span class=n>budget</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>struct</span> <span class=n>igb_q_vector</span> <span class=o>*</span><span class=n>q_vector</span> <span class=o>=</span> <span class=nf>container_of</span><span class=p>(</span><span class=n>napi</span><span class=p>,</span>
</span></span><span class=line><span class=cl>						     <span class=k>struct</span> <span class=n>igb_q_vector</span><span class=p>,</span>
</span></span><span class=line><span class=cl>						     <span class=n>napi</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=c1>// ......
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span><span class=n>q_vector</span><span class=o>-&gt;</span><span class=n>rx</span><span class=p>.</span><span class=n>ring</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// 处理接收到的网络数据包
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=kt>int</span> <span class=n>cleaned</span> <span class=o>=</span> <span class=nf>igb_clean_rx_irq</span><span class=p>(</span><span class=n>q_vector</span><span class=p>,</span> <span class=n>budget</span><span class=p>);</span>	
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// ......
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=k>return</span> <span class=n>work_done</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>追踪到<a href=https://elixir.bootlin.com/linux/v5.10.244/source/drivers/net/ethernet/intel/igb/igb_main.c#L8728><code>igb_clean_rx_irq()</code></a>中就可以看到<code>igb_run_xdp()</code>，即调用<em>Native</em>模式的<code>XDP</code>程序，而且调用<code>igb_run_xdp()</code>的时候skb还没有分配，如果XDP程序的执行结果是<code>XDP_DROP</code>，则会直接丢弃数据包，省去了分配skb的消耗。但如果执行结果是<code>XDP_PASS</code>，就会继续执行后续的处理动作，最终igb的驱动会调<code>napi_gro_receive()</code>处理skb。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>static</span> <span class=kt>int</span> <span class=nf>igb_clean_rx_irq</span><span class=p>(</span><span class=k>struct</span> <span class=n>igb_q_vector</span> <span class=o>*</span><span class=n>q_vector</span><span class=p>,</span> <span class=k>const</span> <span class=kt>int</span> <span class=n>budget</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>struct</span> <span class=n>igb_adapter</span> <span class=o>*</span><span class=n>adapter</span> <span class=o>=</span> <span class=n>q_vector</span><span class=o>-&gt;</span><span class=n>adapter</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>struct</span> <span class=n>igb_ring</span> <span class=o>*</span><span class=n>rx_ring</span> <span class=o>=</span> <span class=n>q_vector</span><span class=o>-&gt;</span><span class=n>rx</span><span class=p>.</span><span class=n>ring</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>struct</span> <span class=n>sk_buff</span> <span class=o>*</span><span class=n>skb</span> <span class=o>=</span> <span class=n>rx_ring</span><span class=o>-&gt;</span><span class=n>skb</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>total_bytes</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>total_packets</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>u16</span> <span class=n>cleaned_count</span> <span class=o>=</span> <span class=nf>igb_desc_unused</span><span class=p>(</span><span class=n>rx_ring</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>xdp_xmit</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>struct</span> <span class=n>xdp_buff</span> <span class=n>xdp</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>rx_buf_pgcnt</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>xdp</span><span class=p>.</span><span class=n>rxq</span> <span class=o>=</span> <span class=o>&amp;</span><span class=n>rx_ring</span><span class=o>-&gt;</span><span class=n>xdp_rxq</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>while</span> <span class=p>(</span><span class=nf>likely</span><span class=p>(</span><span class=n>total_packets</span> <span class=o>&lt;</span> <span class=n>budget</span><span class=p>))</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>union</span> <span class=n>e1000_adv_rx_desc</span> <span class=o>*</span><span class=n>rx_desc</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=k>struct</span> <span class=n>igb_rx_buffer</span> <span class=o>*</span><span class=n>rx_buffer</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=kt>unsigned</span> <span class=kt>int</span> <span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=c1>// ......
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=n>rx_buffer</span> <span class=o>=</span> <span class=nf>igb_get_rx_buffer</span><span class=p>(</span><span class=n>rx_ring</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>rx_buf_pgcnt</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=cm>/* retrieve a buffer from the ring */</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>skb</span><span class=p>)</span> <span class=p>{</span>	<span class=c1>// 没有分配skb，将xdp结构体的成员赋值，为调用XDP做准备
</span></span></span><span class=line><span class=cl><span class=c1></span>			<span class=n>xdp</span><span class=p>.</span><span class=n>data</span> <span class=o>=</span> <span class=nf>page_address</span><span class=p>(</span><span class=n>rx_buffer</span><span class=o>-&gt;</span><span class=n>page</span><span class=p>)</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>				   <span class=n>rx_buffer</span><span class=o>-&gt;</span><span class=n>page_offset</span><span class=p>;</span>
</span></span><span class=line><span class=cl>			<span class=n>xdp</span><span class=p>.</span><span class=n>data_meta</span> <span class=o>=</span> <span class=n>xdp</span><span class=p>.</span><span class=n>data</span><span class=p>;</span>
</span></span><span class=line><span class=cl>			<span class=n>xdp</span><span class=p>.</span><span class=n>data_hard_start</span> <span class=o>=</span> <span class=n>xdp</span><span class=p>.</span><span class=n>data</span> <span class=o>-</span>
</span></span><span class=line><span class=cl>					      <span class=nf>igb_rx_offset</span><span class=p>(</span><span class=n>rx_ring</span><span class=p>);</span>
</span></span><span class=line><span class=cl>			<span class=n>xdp</span><span class=p>.</span><span class=n>data_end</span> <span class=o>=</span> <span class=n>xdp</span><span class=p>.</span><span class=n>data</span> <span class=o>+</span> <span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl>			<span class=c1>// !!! 这里执行了XDP程序
</span></span></span><span class=line><span class=cl><span class=c1></span>			<span class=n>skb</span> <span class=o>=</span> <span class=nf>igb_run_xdp</span><span class=p>(</span><span class=n>adapter</span><span class=p>,</span> <span class=n>rx_ring</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>xdp</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1>// skb交给napi_gro_receive处理, Generic XDP就是在这里被执行的
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=nf>napi_gro_receive</span><span class=p>(</span><span class=o>&amp;</span><span class=n>q_vector</span><span class=o>-&gt;</span><span class=n>napi</span><span class=p>,</span> <span class=n>skb</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>		<span class=cm>/* reset skb pointer */</span>
</span></span><span class=line><span class=cl>		<span class=n>skb</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><a href=https://elixir.bootlin.com/linux/v5.10.244/source/drivers/net/ethernet/intel/igb/igb_main.c#L8444><code>igb_run_xdp()</code></a>的逻辑比较简单，就是判断是否挂载了<code>XDP</code>程序，如果挂载了，就执行挂载的<code>XDP</code>程序，然后对返回的动作处理。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=k>static</span> <span class=k>struct</span> <span class=n>sk_buff</span> <span class=o>*</span><span class=nf>igb_run_xdp</span><span class=p>(</span><span class=k>struct</span> <span class=n>igb_adapter</span> <span class=o>*</span><span class=n>adapter</span><span class=p>,</span>
</span></span><span class=line><span class=cl>				   <span class=k>struct</span> <span class=n>igb_ring</span> <span class=o>*</span><span class=n>rx_ring</span><span class=p>,</span>
</span></span><span class=line><span class=cl>				   <span class=k>struct</span> <span class=n>xdp_buff</span> <span class=o>*</span><span class=n>xdp</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>err</span><span class=p>,</span> <span class=n>result</span> <span class=o>=</span> <span class=n>IGB_XDP_PASS</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>struct</span> <span class=n>bpf_prog</span> <span class=o>*</span><span class=n>xdp_prog</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>u32</span> <span class=n>act</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>rcu_read_lock</span><span class=p>();</span>
</span></span><span class=line><span class=cl>	<span class=n>xdp_prog</span> <span class=o>=</span> <span class=nf>READ_ONCE</span><span class=p>(</span><span class=n>rx_ring</span><span class=o>-&gt;</span><span class=n>xdp_prog</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>xdp_prog</span><span class=p>)</span>	<span class=c1>// 如果没有挂载XDP，直接返回
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=k>goto</span> <span class=n>xdp_out</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>prefetchw</span><span class=p>(</span><span class=n>xdp</span><span class=o>-&gt;</span><span class=n>data_hard_start</span><span class=p>);</span> <span class=cm>/* xdp_frame write */</span>
</span></span><span class=line><span class=cl>	<span class=c1>// 执行XDP程序，根据执行结果设置返回值
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>act</span> <span class=o>=</span> <span class=nf>bpf_prog_run_xdp</span><span class=p>(</span><span class=n>xdp_prog</span><span class=p>,</span> <span class=n>xdp</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=k>switch</span> <span class=p>(</span><span class=n>act</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>case</span> <span class=nl>XDP_PASS</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>case</span> <span class=nl>XDP_TX</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>result</span> <span class=o>=</span> <span class=nf>igb_xdp_xmit_back</span><span class=p>(</span><span class=n>adapter</span><span class=p>,</span> <span class=n>xdp</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>result</span> <span class=o>==</span> <span class=n>IGB_XDP_CONSUMED</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>goto</span> <span class=n>out_failure</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>case</span> <span class=nl>XDP_REDIRECT</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>err</span> <span class=o>=</span> <span class=nf>xdp_do_redirect</span><span class=p>(</span><span class=n>adapter</span><span class=o>-&gt;</span><span class=n>netdev</span><span class=p>,</span> <span class=n>xdp</span><span class=p>,</span> <span class=n>xdp_prog</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>goto</span> <span class=n>out_failure</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=n>result</span> <span class=o>=</span> <span class=n>IGB_XDP_REDIR</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>default</span><span class=o>:</span>
</span></span><span class=line><span class=cl>		<span class=nf>bpf_warn_invalid_xdp_action</span><span class=p>(</span><span class=n>act</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=n>fallthrough</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>case</span> <span class=nl>XDP_ABORTED</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=nl>out_failure</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=nf>trace_xdp_exception</span><span class=p>(</span><span class=n>rx_ring</span><span class=o>-&gt;</span><span class=n>netdev</span><span class=p>,</span> <span class=n>xdp_prog</span><span class=p>,</span> <span class=n>act</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=n>fallthrough</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>case</span> <span class=nl>XDP_DROP</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>result</span> <span class=o>=</span> <span class=n>IGB_XDP_CONSUMED</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=nl>xdp_out</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	<span class=nf>rcu_read_unlock</span><span class=p>();</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nf>ERR_PTR</span><span class=p>(</span><span class=o>-</span><span class=n>result</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>通过分析源码，我们知道了<em>Native</em>模式高效的原因就是它的在数据包处理的早期阶段执行，这个时候还没有为数据包分配skb。</p><h3 id=xdp-generic-model>XDP Generic Model<a hidden class=anchor aria-hidden=true href=#xdp-generic-model>#</a></h3><p><a href=https://elixir.bootlin.com/linux/v5.10.244/source/net/core/dev.c#L6181><code>napi_gro_receive()</code></a> 会调用<code>napi_skb_finish()</code>处理skb。</p><p>上面在分析igb的poll函数时，我们看到了<code>igb_poll()</code>会调用<code>igb_clean_rx_irq()</code>处理数据包，<code>igb_rx_irq()</code>最终会将skb交给<code>napi_gro_receive()</code>，下面是<code>napi_gro_receive()</code>的实现，它会调用其他函数，最终会调用到<code>do_xdp_generic()</code>函数执行以<em>Generic</em>模式挂载的<code>XDP</code>程序。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=kt>gro_result_t</span> <span class=nf>napi_gro_receive</span><span class=p>(</span><span class=k>struct</span> <span class=n>napi_struct</span> <span class=o>*</span><span class=n>napi</span><span class=p>,</span> <span class=k>struct</span> <span class=n>sk_buff</span> <span class=o>*</span><span class=n>skb</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>gro_result_t</span> <span class=n>ret</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>skb_mark_napi_id</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=n>napi</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=nf>trace_napi_gro_receive_entry</span><span class=p>(</span><span class=n>skb</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>skb_gro_reset_offset</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=c1>// 处理skb
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>ret</span> <span class=o>=</span> <span class=nf>napi_skb_finish</span><span class=p>(</span><span class=n>napi</span><span class=p>,</span> <span class=n>skb</span><span class=p>,</span> <span class=nf>dev_gro_receive</span><span class=p>(</span><span class=n>napi</span><span class=p>,</span> <span class=n>skb</span><span class=p>));</span>
</span></span><span class=line><span class=cl>	<span class=nf>trace_napi_gro_receive_exit</span><span class=p>(</span><span class=n>ret</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>ret</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=nf>EXPORT_SYMBOL</span><span class=p>(</span><span class=n>napi_gro_receive</span><span class=p>);</span>
</span></span></code></pre></div><p>从<code>napi_gro_receive()</code>到<code>do_xdp_generic()</code>的调用链非常长，所以下面就以一个图片来展示这个调用链。</p><p><img alt=xdp-generic-call-chain loading=lazy src=/images/posts/linux-ebpf-xdp-models/xdp-generic-call-chain.png></p><p>通过上面的调用链可以看到<code>do_xdp_generic()</code>是被<a href=https://elixir.bootlin.com/linux/v5.10.244/source/net/core/dev.c#L5183><code>__netif_receive_skb_core()</code></a>调用的。<code>__netif_receive_skb_core()</code>干了很多事情，包括：</p><ul><li>执行<em>Generic</em> <code>XDP</code>程序；</li><li>执行<em>tcpdump</em>抓包指令；</li><li>执行挂载在<em>tc ingress</em>上的程序；</li><li>执行挂载在<em>netfilter ingress</em>上的程序；</li><li>分发给对应的网络协议栈；</li></ul><p>从这个函数可以清晰的看到XDP、tcpdump、tc ingress、netfilter和网络协议栈的顺序关系。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=k>static</span> <span class=kt>int</span> <span class=nf>__netif_receive_skb_core</span><span class=p>(</span><span class=k>struct</span> <span class=n>sk_buff</span> <span class=o>**</span><span class=n>pskb</span><span class=p>,</span> <span class=kt>bool</span> <span class=n>pfmemalloc</span><span class=p>,</span>
</span></span><span class=line><span class=cl>				    <span class=k>struct</span> <span class=n>packet_type</span> <span class=o>**</span><span class=n>ppt_prev</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span><span class=nf>static_branch_unlikely</span><span class=p>(</span><span class=o>&amp;</span><span class=n>generic_xdp_needed_key</span><span class=p>))</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=c1>// Generic model XDP program执行点!!!
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=n>ret2</span> <span class=o>=</span> <span class=nf>do_xdp_generic</span><span class=p>(</span><span class=nf>rcu_dereference</span><span class=p>(</span><span class=n>skb</span><span class=o>-&gt;</span><span class=n>dev</span><span class=o>-&gt;</span><span class=n>xdp_prog</span><span class=p>),</span> <span class=n>skb</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>ret2</span> <span class=o>!=</span> <span class=n>XDP_PASS</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>			<span class=n>ret</span> <span class=o>=</span> <span class=n>NET_RX_DROP</span><span class=p>;</span>
</span></span><span class=line><span class=cl>			<span class=k>goto</span> <span class=n>out</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// tcpdump抓包的地方
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nf>list_for_each_entry_rcu</span><span class=p>(</span><span class=n>ptype</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ptype_all</span><span class=p>,</span> <span class=n>list</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>pt_prev</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>ret</span> <span class=o>=</span> <span class=nf>deliver_skb</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=n>pt_prev</span><span class=p>,</span> <span class=n>orig_dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=n>pt_prev</span> <span class=o>=</span> <span class=n>ptype</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>list_for_each_entry_rcu</span><span class=p>(</span><span class=n>ptype</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>skb</span><span class=o>-&gt;</span><span class=n>dev</span><span class=o>-&gt;</span><span class=n>ptype_all</span><span class=p>,</span> <span class=n>list</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>pt_prev</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>ret</span> <span class=o>=</span> <span class=nf>deliver_skb</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=n>pt_prev</span><span class=p>,</span> <span class=n>orig_dev</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=n>pt_prev</span> <span class=o>=</span> <span class=n>ptype</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=cp>#ifdef CONFIG_NET_INGRESS
</span></span></span><span class=line><span class=cl><span class=cp></span>	<span class=k>if</span> <span class=p>(</span><span class=nf>static_branch_unlikely</span><span class=p>(</span><span class=o>&amp;</span><span class=n>ingress_needed_key</span><span class=p>))</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=kt>bool</span> <span class=n>another</span> <span class=o>=</span> <span class=nb>false</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=c1>// tc ingress执行点
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=n>skb</span> <span class=o>=</span> <span class=nf>sch_handle_ingress</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>pt_prev</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ret</span><span class=p>,</span> <span class=n>orig_dev</span><span class=p>,</span>
</span></span><span class=line><span class=cl>					 <span class=o>&amp;</span><span class=n>another</span><span class=p>);</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>another</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>goto</span> <span class=n>another_round</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>skb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>goto</span> <span class=n>out</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=c1>// netfilter ingress执行点
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=k>if</span> <span class=p>(</span><span class=nf>nf_ingress</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>pt_prev</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ret</span><span class=p>,</span> <span class=n>orig_dev</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>goto</span> <span class=n>out</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=cp>#endif
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl>	<span class=c1>// ......
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>	<span class=n>type</span> <span class=o>=</span> <span class=n>skb</span><span class=o>-&gt;</span><span class=n>protocol</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=cm>/* deliver only exact match when indicated */</span>
</span></span><span class=line><span class=cl>    <span class=c1>// IP数据包在此被分发到内核协议栈处理
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=k>if</span> <span class=p>(</span><span class=nf>likely</span><span class=p>(</span><span class=o>!</span><span class=n>deliver_exact</span><span class=p>))</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nf>deliver_ptype_list_skb</span><span class=p>(</span><span class=n>skb</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>pt_prev</span><span class=p>,</span> <span class=n>orig_dev</span><span class=p>,</span> <span class=n>type</span><span class=p>,</span>
</span></span><span class=line><span class=cl>				       <span class=o>&amp;</span><span class=n>ptype_base</span><span class=p>[</span><span class=nf>ntohs</span><span class=p>(</span><span class=n>type</span><span class=p>)</span> <span class=o>&amp;</span>
</span></span><span class=line><span class=cl>						   <span class=n>PTYPE_HASH_MASK</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// ......
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>这篇文章结合Linux源码分析了<code>XDP</code>的<em>Native</em>和<em>Generic</em>模式两种模式的区别：<em>Native</em>模式是在网卡的驱动中执行的，执行的时候还未分配skb，这也要求必须网卡驱动支持<code>XDP</code>才能以<em>Native</em>模式挂载。<em>Generic</em>模式是在网络核心层执行的，此时已经分配了skb，虽然性能不如<em>Native</em>模式，但是仍然在tcpdump和协议栈之前。</p><h2 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h2><ul><li><a href=https://github.com/tohojo/xdp-paper/blob/master/xdp-the-express-data-path.pdf>The eXpress Data Path: Fast Programmable Packet Processing in the Operating System Kernel</a></li><li><a href=https://elixir.bootlin.com/linux/v5.10.244/source>Linux kernel v5.10.244 source</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://rand0m42195.github.io/tags/networking/>Networking</a></li><li><a href=https://rand0m42195.github.io/tags/linux/>Linux</a></li><li><a href=https://rand0m42195.github.io/tags/kernel/>Kernel</a></li><li><a href=https://rand0m42195.github.io/tags/c/>C</a></li><li><a href=https://rand0m42195.github.io/tags/ebpf/>EBPF</a></li><li><a href=https://rand0m42195.github.io/tags/xdp/>XDP</a></li></ul><nav class=paginav><a class=prev href=https://rand0m42195.github.io/posts/writing-an-interpreter-in-rust/><span class=title>« 上一页</span><br><span>Writing An Interpreter In Rust (1)</span>
</a><a class=next href=https://rand0m42195.github.io/posts/linux-networking-socket-syscall/><span class=title>下一页 »</span><br><span>Linux 网络编程——socket 系统调用实现剖析</span></a></nav></footer><div id=comments><script src=https://giscus.app/client.js data-repo=rand0m42195/rand0m42195.github.io data-repo-id=R_kgDOPzDcOw data-category=Announcements data-category-id=DIC_kwDOPzDcO84CvpUm data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://rand0m42195.github.io/>rand0m's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>